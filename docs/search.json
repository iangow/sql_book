[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SQL for Data Analysis using R",
    "section": "",
    "text": "Preface\nThis “book” is a collection of notes made as I work through Tanimura (2021). An alternative title might have been “Data Analysis with Data Stored in Databases”; while SQL is the language used in Tanimura (2021) to do the analysis, this is in some ways a minor detail. My view is that one can easy do “SQL” analysis using the dplyr package in R (this uses dbplyr behind the scenes … mostly). The dplyr package will quietly translate R code into SQL for the user.\nAn advantage of using dplyr rather than SQL directly is that one doesn’t need to learn as much SQL. In principle, one could use dplyr without knowing any SQL. Given that dplyr and R can be used to analyse data from other data sources, this reduces the amount that is needed to be learnt to do analysis. Additionally, one could write code to analyse data from a database and then easily reuse the code for data from a CSV file.\nNotwithstanding the discussion in the previous paragraph, I recommend that people who find themselves using SQL-driven databases a lot learn some SQL. This view is implicitly endorsed by Hadley Wickham with the inclusion of a significant amount of material intended to teach SQL to readers of “R for Data Science”. While we include a brief primer on SQL for dplyr users here, clearly an excellent source for learning SQL is Tanimura (2021) itself.\nAnother benefit of using R is that we can do more with R. Tanimura (2021) includes many plots of data produced using SQL, but the code to make the plots is not included. In contrast, here I will include code to produce the data as well as code to make plots (where applicable).\nMy view is that the material here might be useful to someone who is using Tanimura (2021) and wants to see how the ideas there can be implemented using R, while at the same time being useful to someone who knows (or is looking to learn) R and is looking for realistic data sets to work on.\n\n\n\n\nTanimura, C. 2021. SQL for Data Analysis. O’Reilly Media. https://books.google.com.au/books?id=ojhCEAAAQBAJ."
  },
  {
    "objectID": "chapter_2.html#missing-data",
    "href": "chapter_2.html#missing-data",
    "title": "2  Preparing Data for Analysis",
    "section": "2.1 Missing data",
    "text": "2.1 Missing data\n\nlibrary(tidyverse)\nlibrary(DBI)\n\n\npg <- dbConnect(RPostgres::Postgres(), bigint = \"integer\")\ndbExecute(pg, \"SET search_path TO sql_book\")\n\n\ndates_sql <-\n   \"SELECT * \n    FROM generate_series('2000-01-01'::timestamp,'2030-12-31', '1 day')\"\n\ndates <- \n  tbl(pg, sql(dates_sql)) %>%\n  rename(date = generate_series)\n\ndates_processed <-\n  dates %>%\n  mutate(date_key = as.integer(to_char(date, 'yyyymmdd')),\n         day_of_month = as.integer(date_part('day',date)),\n         day_of_year = as.integer(date_part('doy', date)),\n         day_of_week = as.integer(date_part('dow', date)),\n         day_name  = trim(to_char(date, 'Day')),\n         day_short_name = trim(to_char(date, 'Dy')),\n         week_number = as.integer(date_part('week', date)),\n         week_of_month = as.integer(to_char(date,'W')),\n         week = as.Date(date_trunc('week', date)),\n         month_number = as.integer(date_part('month',date)),\n         month_name = trim(to_char(date, 'Month')),\n         month_short_name = trim(to_char(date, 'Mon')),\n         first_day_of_month = as.Date(date_trunc('month', date)),\n         last_day_of_month = as.Date(date_trunc('month', date) +\n                                       sql(\"interval '1 month' -\n                                            interval '1 day'\")),\n         quarter_number = as.integer(date_part('quarter', date)),\n         quarter_name = trim('Q' %||% as.integer(date_part('quarter', date))),\n         first_day_of_quarter = as.Date(date_trunc('quarter', date)),\n         last_day_of_quarter = as.Date(date_trunc('quarter', date) + \n                                         sql(\"interval '3 months' -\n                                              interval '1 day'\")),\n         year = as.integer(date_part('year', date)),\n         decade = as.integer(date_part('decade', date)) * 10,\n         century = as.integer(date_part('century', date)))\n\ndates_processed %>%\n  collect(n = 10)\n\n# A tibble: 10 × 22\n   date                date_key day_of…¹ day_o…² day_o…³ day_n…⁴ day_s…⁵ week_…⁶\n   <dttm>                 <int>    <int>   <int>   <int> <chr>   <chr>     <int>\n 1 2000-01-01 00:00:00 20000101        1       1       6 Saturd… Sat          52\n 2 2000-01-02 00:00:00 20000102        2       2       0 Sunday  Sun          52\n 3 2000-01-03 00:00:00 20000103        3       3       1 Monday  Mon           1\n 4 2000-01-04 00:00:00 20000104        4       4       2 Tuesday Tue           1\n 5 2000-01-05 00:00:00 20000105        5       5       3 Wednes… Wed           1\n 6 2000-01-06 00:00:00 20000106        6       6       4 Thursd… Thu           1\n 7 2000-01-07 00:00:00 20000107        7       7       5 Friday  Fri           1\n 8 2000-01-08 00:00:00 20000108        8       8       6 Saturd… Sat           1\n 9 2000-01-09 00:00:00 20000109        9       9       0 Sunday  Sun           1\n10 2000-01-10 00:00:00 20000110       10      10       1 Monday  Mon           2\n# … with 14 more variables: week_of_month <int>, week <date>,\n#   month_number <int>, month_name <chr>, month_short_name <chr>,\n#   first_day_of_month <date>, last_day_of_month <date>, quarter_number <int>,\n#   quarter_name <chr>, first_day_of_quarter <date>,\n#   last_day_of_quarter <date>, year <int>, decade <dbl>, century <int>, and\n#   abbreviated variable names ¹​day_of_month, ²​day_of_year, ³​day_of_week,\n#   ⁴​day_name, ⁵​day_short_name, ⁶​week_number\n\ndates_processed %>%\n  show_query()\n\n<SQL>\nSELECT\n  *,\n  CAST(to_char(\"date\", 'yyyymmdd') AS INTEGER) AS \"date_key\",\n  CAST(date_part('day', \"date\") AS INTEGER) AS \"day_of_month\",\n  CAST(date_part('doy', \"date\") AS INTEGER) AS \"day_of_year\",\n  CAST(date_part('dow', \"date\") AS INTEGER) AS \"day_of_week\",\n  trim(to_char(\"date\", 'Day')) AS \"day_name\",\n  trim(to_char(\"date\", 'Dy')) AS \"day_short_name\",\n  CAST(date_part('week', \"date\") AS INTEGER) AS \"week_number\",\n  CAST(to_char(\"date\", 'W') AS INTEGER) AS \"week_of_month\",\n  CAST(date_trunc('week', \"date\") AS DATE) AS \"week\",\n  CAST(date_part('month', \"date\") AS INTEGER) AS \"month_number\",\n  trim(to_char(\"date\", 'Month')) AS \"month_name\",\n  trim(to_char(\"date\", 'Mon')) AS \"month_short_name\",\n  CAST(date_trunc('month', \"date\") AS DATE) AS \"first_day_of_month\",\n  CAST(date_trunc('month', \"date\") + interval '1 month' -\n                                            interval '1 day' AS DATE) AS \"last_day_of_month\",\n  CAST(date_part('quarter', \"date\") AS INTEGER) AS \"quarter_number\",\n  trim('Q' || CAST(date_part('quarter', \"date\") AS INTEGER)) AS \"quarter_name\",\n  CAST(date_trunc('quarter', \"date\") AS DATE) AS \"first_day_of_quarter\",\n  CAST(date_trunc('quarter', \"date\") + interval '3 months' -\n                                              interval '1 day' AS DATE) AS \"last_day_of_quarter\",\n  CAST(date_part('year', \"date\") AS INTEGER) AS \"year\",\n  CAST(date_part('decade', \"date\") AS INTEGER) * 10.0 AS \"decade\",\n  CAST(date_part('century', \"date\") AS INTEGER) AS \"century\"\nFROM (\n  SELECT \"generate_series\" AS \"date\"\n  FROM (\nSELECT * \n    FROM generate_series('2000-01-01'::timestamp,'2030-12-31', '1 day')\n  ) \"q01\"\n) \"q02\"\n\n\n\n\n\n\nctry_pops <-\n  tribble(\n  ~country, ~year_1980,  ~year_1990, ~year_2000, ~year_2010,\n  \"Canada\", 24593, 27791, 31100, 34207,\n  \"Mexico\", 68347, 84634, 99775, 114061,\n  \"United States\", 227225, 249623, 282162, 309326\n)\n\nctry_pops %>%\n  pivot_longer(cols = -country, \n               names_to = \"year\",\n               names_prefix = \"year_\",\n               values_ptypes = integer(),\n               values_to = \"population\")\n\n# A tibble: 12 × 3\n   country       year  population\n   <chr>         <chr>      <int>\n 1 Canada        1980       24593\n 2 Canada        1990       27791\n 3 Canada        2000       31100\n 4 Canada        2010       34207\n 5 Mexico        1980       68347\n 6 Mexico        1990       84634\n 7 Mexico        2000       99775\n 8 Mexico        2010      114061\n 9 United States 1980      227225\n10 United States 1990      249623\n11 United States 2000      282162\n12 United States 2010      309326\n\n\n\nctry_pops_db <- copy_to(pg, ctry_pops)\n\n\nctry_pops_db %>%\n  pivot_longer(cols = -country, \n               names_to = \"year\",\n               names_prefix = \"year_\",\n               values_to = \"population\") %>%\n  show_query()\n\n<SQL>\n(\n  (\n    (\n      SELECT \"country\", '1980' AS \"year\", \"year_1980\" AS \"population\"\n      FROM \"ctry_pops\"\n    )\n    UNION ALL\n    (\n      SELECT \"country\", '1990' AS \"year\", \"year_1990\" AS \"population\"\n      FROM \"ctry_pops\"\n    )\n  )\n  UNION ALL\n  (\n    SELECT \"country\", '2000' AS \"year\", \"year_2000\" AS \"population\"\n    FROM \"ctry_pops\"\n  )\n)\nUNION ALL\n(\n  SELECT \"country\", '2010' AS \"year\", \"year_2010\" AS \"population\"\n  FROM \"ctry_pops\"\n)\n\n\n\n\n\n\nTanimura, C. 2021. SQL for Data Analysis. O’Reilly Media. https://books.google.com.au/books?id=ojhCEAAAQBAJ."
  },
  {
    "objectID": "chapter_3.html#date-datetime-and-time-manipulations",
    "href": "chapter_3.html#date-datetime-and-time-manipulations",
    "title": "3  Time Series Analysis",
    "section": "3.1 Date, Datetime, and Time Manipulations",
    "text": "3.1 Date, Datetime, and Time Manipulations\n\npg <- dbConnect(RPostgres::Postgres(), bigint = \"integer\")\ndbExecute(pg, \"SET search_path TO sql_book\")\n\nTanimura (2021) points out that often “timestamps in the database are not encoded with the time zone, and you will need to consult with the source or developer to figure out how your data was stored.” When pushing data to a PostgreSQL database, I use the timestamp with time zone type as much as possible.\nTanimura (2021) provides the following example, which is interesting because the west coast of the United States would not be on the PST time zone at that time of year. Instead, it would be on PDT.\n\nSELECT '2020-09-01 00:00:00 -0' AT TIME ZONE 'pst';\n\n\n1 records\n\n\ntimezone\n\n\n\n\n2020-08-31 16:00:00\n\n\n\n\n\n\nSELECT '2020-09-01 00:00:00 -0' AT TIME ZONE 'pdt';\n\n\n1 records\n\n\ntimezone\n\n\n\n\n2020-08-31 17:00:00\n\n\n\n\n\nI think most people barely know the difference between PST and PDT and even fewer would know the exact dates that one switches from one to the other. A better approach is to use a time zone that encodes information about when PDT is used and when PST is used. In PostgreSQL, the table pg_timezone_names has information that we need.\n\nSELECT * \nFROM pg_timezone_names\nWHERE name ~ '^US/';\n\n\nDisplaying records 1 - 10\n\n\nname\nabbrev\nutc_offset\nis_dst\n\n\n\n\nUS/Alaska\nAKDT\n-08:00:00\nTRUE\n\n\nUS/Pacific\nPDT\n-07:00:00\nTRUE\n\n\nUS/Eastern\nEDT\n-04:00:00\nTRUE\n\n\nUS/Michigan\nEDT\n-04:00:00\nTRUE\n\n\nUS/Arizona\nMST\n-07:00:00\nFALSE\n\n\nUS/Indiana-Starke\nCDT\n-05:00:00\nTRUE\n\n\nUS/Aleutian\nHDT\n-09:00:00\nTRUE\n\n\nUS/Hawaii\nHST\n-10:00:00\nFALSE\n\n\nUS/East-Indiana\nEDT\n-04:00:00\nTRUE\n\n\nUS/Central\nCDT\n-05:00:00\nTRUE\n\n\n\n\n\n\nSELECT * \nFROM pg_timezone_names\nWHERE abbrev IN ('PDT', 'PST') \nORDER BY name DESC\nLIMIT 5;\n\n\n5 records\n\n\nname\nabbrev\nutc_offset\nis_dst\n\n\n\n\nUS/Pacific\nPDT\n-07:00:00\nTRUE\n\n\nPST8PDT\nPDT\n-07:00:00\nTRUE\n\n\nMexico/BajaNorte\nPDT\n-07:00:00\nTRUE\n\n\nCanada/Pacific\nPDT\n-07:00:00\nTRUE\n\n\nAsia/Manila\nPST\n08:00:00\nFALSE\n\n\n\n\n\n\nSELECT \n    '2020-09-01 00:00:00 -0' AT TIME ZONE 'US/Pacific',\n    '2020-09-01 00:00:00 -0' AT TIME ZONE 'PDT';\n\n\n1 records\n\n\ntimezone\ntimezone..2\n\n\n\n\n2020-08-31 17:00:00\n2020-08-31 17:00:00\n\n\n\n\n\n\nSELECT     \n    '2020-12-01 00:00:00 -0' AT TIME ZONE 'US/Pacific',\n    '2020-12-01 00:00:00 -0' AT TIME ZONE 'PST';\n\n\n1 records\n\n\ntimezone\ntimezone..2\n\n\n\n\n2020-11-30 16:00:00\n2020-11-30 16:00:00\n\n\n\n\n\n\n3.1.1 Date and Timestamp Format Conversions\nAs discussed in Tanimura (2021), PostgreSQL has a rich array of functions for converting dates and times and extracting such information as months and days of the week.\n\nSELECT date_trunc('month','2020-10-04 12:33:35'::timestamp);\n\n\n1 records\n\n\ndate_trunc\n\n\n\n\n2020-10-01\n\n\n\n\n\nOne such function\n\na_time_df <- tbl(pg, sql(\"SELECT '2020-10-04 12:33:35'::timestamp AS a_time\"))\na_time_df %>% \n  mutate(a_trunced_time = date_trunc('month', a_time))\n\n# Source:   SQL [1 x 2]\n# Database: postgres  [iangow@/tmp:5432/iangow]\n  a_time              a_trunced_time     \n  <dttm>              <dttm>             \n1 2020-10-04 12:33:35 2020-10-01 00:00:00\n\na_time_df %>% \n  mutate(a_trunced_time = date_trunc('month', a_time)) %>%\n  show_query()\n\n<SQL>\nSELECT *, date_trunc('month', \"a_time\") AS \"a_trunced_time\"\nFROM (SELECT '2020-10-04 12:33:35'::timestamp AS a_time) \"q01\"\n\na_time_df %>%\n  collect()\n\n# A tibble: 1 × 1\n  a_time             \n  <dttm>             \n1 2020-10-04 12:33:35\n\n\n\na_time_df <- tbl(pg, sql(\"SELECT '2020-10-04 12:33:35 US/Pacific'::timestamp with time zone AS a_time\"))\n\na_time_df %>% \n  mutate(a_trunced_time = date_trunc('month', a_time)) \n\n# Source:   SQL [1 x 2]\n# Database: postgres  [iangow@/tmp:5432/iangow]\n  a_time              a_trunced_time     \n  <dttm>              <dttm>             \n1 2020-10-04 19:33:35 2020-10-01 00:00:00\n\na_time_df %>% \n  mutate(a_trunced_time = date_trunc('month', a_time)) %>%\n  show_query()\n\n<SQL>\nSELECT *, date_trunc('month', \"a_time\") AS \"a_trunced_time\"\nFROM (SELECT '2020-10-04 12:33:35 US/Pacific'::timestamp with time zone AS a_time) \"q01\"\n\na_time_df %>%\n  collect()\n\n# A tibble: 1 × 1\n  a_time             \n  <dttm>             \n1 2020-10-04 19:33:35\n\n\n\na_time_df %>%\n  mutate(new_time = a_time + sql(\"interval '3 hours'\")) %>%\n  collect()\n\n# A tibble: 1 × 2\n  a_time              new_time           \n  <dttm>              <dttm>             \n1 2020-10-04 19:33:35 2020-10-04 22:33:35"
  },
  {
    "objectID": "chapter_3.html#the-retail-sales-data-set",
    "href": "chapter_3.html#the-retail-sales-data-set",
    "title": "3  Time Series Analysis",
    "section": "3.2 The Retail Sales Data Set",
    "text": "3.2 The Retail Sales Data Set\n\nSELECT sales_month, sales\nFROM retail_sales\nWHERE kind_of_business = 'Retail and food services sales, total'\nORDER BY 1\n\n\nDisplaying records 1 - 10\n\n\nsales_month\nsales\n\n\n\n\n1992-01-01\n146376\n\n\n1992-02-01\n147079\n\n\n1992-03-01\n159336\n\n\n1992-04-01\n163669\n\n\n1992-05-01\n170068\n\n\n1992-06-01\n168663\n\n\n1992-07-01\n169890\n\n\n1992-08-01\n170364\n\n\n1992-09-01\n164617\n\n\n1992-10-01\n173655\n\n\n\n\n\n\nretail_sales <- tbl(pg, \"retail_sales\")\nretail_sales %>%\n  filter(kind_of_business == 'Retail and food services sales, total') %>%\n  select(sales_month, sales) %>%\n  arrange(sales_month) %>%\n  ggplot(aes(x = sales_month, y = sales)) +\n  geom_line()\n\n\n\n\n\nSELECT date_part('year',sales_month) as sales_year,\n    sum(sales) as sales\nFROM retail_sales\nWHERE kind_of_business = 'Retail and food services sales, total'\nGROUP BY 1\n;\n\n\nDisplaying records 1 - 10\n\n\nsales_year\nsales\n\n\n\n\n2007\n4439733\n\n\n2005\n4085746\n\n\n1992\n2014102\n\n\n2011\n4598302\n\n\n2014\n5215656\n\n\n2006\n4294359\n\n\n2010\n4284968\n\n\n2001\n3378906\n\n\n2019\n6218002\n\n\n2018\n6001623\n\n\n\n\n\n\nretail_sales %>%\n  filter(kind_of_business == 'Retail and food services sales, total') %>%\n  mutate(sales_year = date_part('year', sales_month)) %>%\n  group_by(sales_year) %>%\n  summarize(sales = sum(sales, na.rm = TRUE)) %>%\n  arrange(sales_year) %>%\n  ggplot(aes(x = sales_year, y = sales)) +\n  geom_line()\n\n\n\n\n\nSELECT date_part('year',sales_month) as sales_year, \n  kind_of_business, sum(sales) as sales\nFROM retail_sales\nWHERE kind_of_business IN \n          ('Book stores',\n           'Sporting goods stores',\n           'Hobby, toy, and game stores')\nGROUP BY 1,2\nORDER BY 1;\n\n\nDisplaying records 1 - 10\n\n\nsales_year\nkind_of_business\nsales\n\n\n\n\n1992\nSporting goods stores\n15583\n\n\n1992\nHobby, toy, and game stores\n11251\n\n\n1992\nBook stores\n8327\n\n\n1993\nHobby, toy, and game stores\n11651\n\n\n1993\nSporting goods stores\n16791\n\n\n1993\nBook stores\n9108\n\n\n1994\nSporting goods stores\n18825\n\n\n1994\nBook stores\n10107\n\n\n1994\nHobby, toy, and game stores\n12850\n\n\n1995\nHobby, toy, and game stores\n13714\n\n\n\n\n\n\nretail_sales %>%\n  filter(kind_of_business %in% \n           c('Book stores',\n             'Sporting goods stores',\n             'Hobby, toy, and game stores')) %>%\n  mutate(sales_year = date_part('year', sales_month)) %>%\n  group_by(sales_year, kind_of_business) %>%\n  summarize(sales = sum(sales, na.rm = TRUE), .groups = \"drop\") %>%\n  arrange(sales_year) %>%\n  ggplot(aes(x = sales_year, y = sales, color = kind_of_business)) +\n  geom_line() +\n  theme(legend.position = \"top\")\n\n\n\n\n\nSELECT sales_month, kind_of_business, sales\nFROM retail_sales\nWHERE kind_of_business IN ('Men''s clothing stores','Women''s clothing stores')\nORDER BY 1,2;\n\n\nDisplaying records 1 - 10\n\n\nsales_month\nkind_of_business\nsales\n\n\n\n\n1992-01-01\nMen’s clothing stores\n701\n\n\n1992-01-01\nWomen’s clothing stores\n1873\n\n\n1992-02-01\nMen’s clothing stores\n658\n\n\n1992-02-01\nWomen’s clothing stores\n1991\n\n\n1992-03-01\nMen’s clothing stores\n731\n\n\n1992-03-01\nWomen’s clothing stores\n2403\n\n\n1992-04-01\nMen’s clothing stores\n816\n\n\n1992-04-01\nWomen’s clothing stores\n2665\n\n\n1992-05-01\nMen’s clothing stores\n856\n\n\n1992-05-01\nWomen’s clothing stores\n2752\n\n\n\n\n\n\nretail_sales %>%\n  filter(kind_of_business %in% c(\"Men's clothing stores\",\n                                 \"Women's clothing stores\")) %>%\n  select(sales_month, kind_of_business, sales) %>%\n  arrange(sales_month) %>%\n  ggplot(aes(x = sales_month, y = sales, color = kind_of_business)) +\n  geom_line() +\n  theme(legend.position = \"top\")\n\n\n\n\n\nSELECT date_part('year',sales_month) as sales_year,\n  kind_of_business, sum(sales) as sales\nFROM retail_sales\nWHERE kind_of_business IN \n        ('Men''s clothing stores',\n        'Women''s clothing stores')\nGROUP BY 1, 2\nORDER BY 1, 2;\n\n\nDisplaying records 1 - 10\n\n\nsales_year\nkind_of_business\nsales\n\n\n\n\n1992\nMen’s clothing stores\n10179\n\n\n1992\nWomen’s clothing stores\n31815\n\n\n1993\nMen’s clothing stores\n9962\n\n\n1993\nWomen’s clothing stores\n32350\n\n\n1994\nMen’s clothing stores\n10032\n\n\n1994\nWomen’s clothing stores\n30585\n\n\n1995\nMen’s clothing stores\n9315\n\n\n1995\nWomen’s clothing stores\n28696\n\n\n1996\nMen’s clothing stores\n9546\n\n\n1996\nWomen’s clothing stores\n28238\n\n\n\n\n\n\nretail_sales %>%\n  filter(kind_of_business %in% \n           c(\"Men's clothing stores\",\n             \"Women's clothing stores\")) %>%\n  mutate(sales_year = date_part('year', sales_month)) %>%\n  group_by(sales_year, kind_of_business) %>%\n  summarize(sales = sum(sales, na.rm = TRUE), .groups = \"drop\") %>%\n  arrange(sales_year) %>%\n  ggplot(aes(x = sales_year, y = sales, color = kind_of_business)) +\n  geom_line() +\n  theme(legend.position = \"top\")\n\n\n\n\n\nSELECT date_part('year', sales_month) AS sales_year,\n  sum(CASE WHEN kind_of_business = 'Women''s clothing stores' \n          then sales \n          END) AS womens_sales,\n  sum(CASE WHEN kind_of_business = 'Men''s clothing stores' \n          then sales \n          END) AS mens_sales\nFROM retail_sales\nWHERE kind_of_business IN \n   ('Men''s clothing stores',\n    'Women''s clothing stores')\nGROUP BY 1\nORDER BY 1;\n\n\nDisplaying records 1 - 10\n\n\nsales_year\nwomens_sales\nmens_sales\n\n\n\n\n1992\n31815\n10179\n\n\n1993\n32350\n9962\n\n\n1994\n30585\n10032\n\n\n1995\n28696\n9315\n\n\n1996\n28238\n9546\n\n\n1997\n27822\n10069\n\n\n1998\n28332\n10196\n\n\n1999\n29549\n9667\n\n\n2000\n31447\n9507\n\n\n2001\n31453\n8625\n\n\n\n\n\n\npivoted_sales <-\n  retail_sales %>%\n  filter(kind_of_business %in% \n           c(\"Men's clothing stores\",\n             \"Women's clothing stores\")) %>%\n  mutate(kind_of_business = if_else(kind_of_business == \"Women's clothing stores\",\n                                    \"womens\", \"mens\"),\n         sales_year = date_part('year', sales_month)) %>%\n  group_by(sales_year, kind_of_business) %>%\n  summarize(sales = sum(sales, na.rm = TRUE), .groups = \"drop\") %>%\n  pivot_wider(id_cols = \"sales_year\",\n              names_from = \"kind_of_business\",\n              names_glue = \"{kind_of_business}_{.value}\",\n              values_from = \"sales\")  \n\npivoted_sales %>%\n  show_query()\n\n<SQL>\nSELECT\n  \"sales_year\",\n  MAX(CASE WHEN (\"kind_of_business\" = 'mens') THEN \"sales\" END) AS \"mens_sales\",\n  MAX(CASE WHEN (\"kind_of_business\" = 'womens') THEN \"sales\" END) AS \"womens_sales\"\nFROM (\n  SELECT \"sales_year\", \"kind_of_business\", SUM(\"sales\") AS \"sales\"\n  FROM (\n    SELECT\n      \"sales_month\",\n      \"naics_code\",\n      CASE WHEN (\"kind_of_business\" = 'Women''s clothing stores') THEN 'womens' WHEN NOT (\"kind_of_business\" = 'Women''s clothing stores') THEN 'mens' END AS \"kind_of_business\",\n      \"reason_for_null\",\n      \"sales\",\n      date_part('year', \"sales_month\") AS \"sales_year\"\n    FROM \"retail_sales\"\n    WHERE (\"kind_of_business\" IN ('Men''s clothing stores', 'Women''s clothing stores'))\n  ) \"q01\"\n  GROUP BY \"sales_year\", \"kind_of_business\"\n) \"q02\"\nGROUP BY \"sales_year\"\n\npivoted_sales %>%\n  arrange(sales_year) %>%\n  collect(n = 10) %>%\n  knitr::kable()\n\n\n\n\nsales_year\nmens_sales\nwomens_sales\n\n\n\n\n1992\n10179\n31815\n\n\n1993\n9962\n32350\n\n\n1994\n10032\n30585\n\n\n1995\n9315\n28696\n\n\n1996\n9546\n28238\n\n\n1997\n10069\n27822\n\n\n1998\n10196\n28332\n\n\n1999\n9667\n29549\n\n\n2000\n9507\n31447\n\n\n2001\n8625\n31453\n\n\n\n\n\n\npivoted_sales %>%\n  filter(sales_year <= 2019) %>%\n  group_by(sales_year) %>%\n  mutate(womens_minus_mens = womens_sales - mens_sales,\n         mens_minus_womens = mens_sales - womens_sales) %>%\n  select(sales_year, womens_minus_mens, mens_minus_womens) %>%\n  arrange(sales_year) %>%\n  ggplot(aes(y = womens_minus_mens, x = sales_year)) +\n  geom_line()\n\n\n\n\n\npivoted_sales %>%\n  filter(sales_year <= 2019) %>%\n  group_by(sales_year) %>%\n  mutate(womens_times_of_mens = womens_sales / mens_sales) %>%\n  arrange(sales_year) %>%\n  ggplot(aes(y = womens_times_of_mens, x = sales_year)) +\n  geom_line()\n\n\n\n\n\npivoted_sales %>%\n  filter(sales_year <= 2019) %>%\n  group_by(sales_year) %>%\n  mutate(womens_pct_of_mens = (womens_sales / mens_sales - 1) * 100) %>%\n  arrange(sales_year) %>%\n  ggplot(aes(y = womens_pct_of_mens, x = sales_year)) +\n  geom_line()\n\n\n\n\n\nretail_sales %>%\n  filter(kind_of_business %in% \n           c(\"Men's clothing stores\",\n             \"Women's clothing stores\")) %>%\n  group_by(sales_month) %>%\n  mutate(total_sales = sum(sales)) %>%\n  ungroup() %>%\n  mutate(pct_total_sales = sales * 100 / total_sales) %>%\n  select(sales_month, kind_of_business, pct_total_sales) %>%\n  collect(n = 3)\n\nWarning: Missing values are always removed in SQL aggregation functions.\nUse `na.rm = TRUE` to silence this warning\nThis warning is displayed once every 8 hours.\n\n\n# A tibble: 3 × 3\n  sales_month kind_of_business        pct_total_sales\n  <date>      <chr>                             <dbl>\n1 1992-01-01  Women's clothing stores            72.8\n2 1992-01-01  Men's clothing stores              27.2\n3 1992-02-01  Men's clothing stores              24.8\n\n\n\nretail_sales %>%\n  filter(kind_of_business %in% \n           c(\"Men's clothing stores\",\n             \"Women's clothing stores\")) %>%\n  group_by(sales_month) %>%\n  mutate(total_sales = sum(sales)) %>%\n  ungroup() %>%\n  mutate(pct_total_sales = sales * 100 / total_sales) %>%\n  show_query()\n\n<SQL>\nSELECT *, (\"sales\" * 100.0) / \"total_sales\" AS \"pct_total_sales\"\nFROM (\n  SELECT *, SUM(\"sales\") OVER (PARTITION BY \"sales_month\") AS \"total_sales\"\n  FROM \"retail_sales\"\n  WHERE (\"kind_of_business\" IN ('Men''s clothing stores', 'Women''s clothing stores'))\n) \"q01\"\n\n\n\nretail_sales %>%\n  filter(kind_of_business %in% \n           c(\"Men's clothing stores\",\n             \"Women's clothing stores\")) %>%\n  group_by(sales_month) %>%\n  mutate(total_sales = sum(sales)) %>%\n  ungroup() %>%\n  mutate(pct_total_sales = sales * 100 / total_sales) %>%\n  ggplot(aes(y = pct_total_sales, x = sales_month, color = kind_of_business)) +\n  geom_line()\n\n\n\n\n\nretail_sales %>%\n  filter(kind_of_business == \"Women's clothing stores\") %>%\n  mutate(sales_year = date_part('year',sales_month)) %>%\n  group_by(sales_year) %>%\n  summarize(sales = sum(sales, na.rm = TRUE)) %>%\n  ungroup() %>%\n  window_order(sales_year) %>%\n  mutate(index_sales = first(sales),\n         pct_from_index = (sales/index_sales - 1) * 100)\n\n# Source:     SQL [?? x 4]\n# Database:   postgres  [iangow@/tmp:5432/iangow]\n# Ordered by: sales_year\n   sales_year sales index_sales pct_from_index\n        <dbl> <dbl>       <dbl>          <dbl>\n 1       1992 31815       31815           0   \n 2       1993 32350       31815           1.68\n 3       1994 30585       31815          -3.87\n 4       1995 28696       31815          -9.80\n 5       1996 28238       31815         -11.2 \n 6       1997 27822       31815         -12.6 \n 7       1998 28332       31815         -10.9 \n 8       1999 29549       31815          -7.12\n 9       2000 31447       31815          -1.16\n10       2001 31453       31815          -1.14\n# … with more rows\n\n\n\nretail_sales %>%\n  filter(kind_of_business %in% c(\"Women's clothing stores\",\n                                 \"Men's clothing stores\"),\n         sales_month <= '2019-12-31') %>%\n  mutate(sales_year = date_part('year',sales_month)) %>%\n  group_by(kind_of_business, sales_year) %>%\n  summarize(sales = sum(sales, na.rm = TRUE), .groups = \"drop\") %>%\n  group_by(kind_of_business) %>%\n  window_order(sales_year) %>%\n  mutate(index_sales = first(sales),\n         pct_from_index = (sales/index_sales - 1) * 100) %>%\n  ungroup() %>%\n  ggplot(aes(y = pct_from_index, x = sales_year, color = kind_of_business)) +\n  geom_line()\n\n\n\n\n\nretail_sales %>%\n  filter(kind_of_business == \"Women's clothing stores\") %>%\n  window_order(sales_month) %>%\n  window_frame(-11, 0) %>%\n  mutate(moving_avg = mean(sales, na.rm = TRUE),\n         records_count = n()) %>%\n  select(sales_month, moving_avg, records_count) %>%\n  collect(n = 10)\n\n# A tibble: 10 × 3\n   sales_month moving_avg records_count\n   <date>           <dbl>         <int>\n 1 1992-01-01       1873              1\n 2 1992-02-01       1932              2\n 3 1992-03-01       2089              3\n 4 1992-04-01       2233              4\n 5 1992-05-01       2337.             5\n 6 1992-06-01       2351.             6\n 7 1992-07-01       2354.             7\n 8 1992-08-01       2392.             8\n 9 1992-09-01       2411.             9\n10 1992-10-01       2445.            10\n\n\n\n\n\n\nTanimura, C. 2021. SQL for Data Analysis. O’Reilly Media. https://books.google.com.au/books?id=ojhCEAAAQBAJ."
  },
  {
    "objectID": "chapter_4.html",
    "href": "chapter_4.html",
    "title": "4  Cohorts",
    "section": "",
    "text": "pg <- dbConnect(RPostgres::Postgres(), bigint = \"integer\")\ndbExecute(pg, \"SET search_path TO sql_book\")\n\n\nSELECT id_bioguide ,min(term_start) AS first_term\nFROM legislators_terms \nGROUP BY 1\nLIMIT 10;\n\n\nDisplaying records 1 - 10\n\n\nid_bioguide\nfirst_term\n\n\n\n\nA000118\n1975-01-14\n\n\nP000281\n1933-03-09\n\n\nK000039\n1933-03-09\n\n\nA000306\n1907-12-02\n\n\nO000095\n1949-01-03\n\n\nB000937\n1913-04-07\n\n\nS000038\n1912-01-01\n\n\nS000657\n1901-12-02\n\n\nP000383\n1873-12-01\n\n\nL000058\n1887-12-05\n\n\n\n\n\n\nWITH first_terms AS (\n      SELECT id_bioguide, min(term_start) AS first_term\n      FROM legislators_terms \n      GROUP BY 1) \nSELECT date_part('year', age(b.term_start, a.first_term)) AS period,\n    count(distinct a.id_bioguide) as cohort_retained\nFROM first_terms a\nJOIN legislators_terms b on a.id_bioguide = b.id_bioguide \nGROUP BY 1\nLIMIT 10;\n\n\nDisplaying records 1 - 10\n\n\nperiod\ncohort_retained\n\n\n\n\n0\n12518\n\n\n1\n3600\n\n\n2\n3619\n\n\n3\n1831\n\n\n4\n3210\n\n\n5\n1744\n\n\n6\n2385\n\n\n7\n1360\n\n\n8\n1607\n\n\n9\n1028\n\n\n\n\n\n\nlegislators_terms <- tbl(pg, \"legislators_terms\")\nfirst_terms <- \n  legislators_terms %>%\n  group_by(id_bioguide) %>%\n  summarize(first_term = min(term_start, na.rm = TRUE))\n\ncohorts <-\n  legislators_terms %>%\n  inner_join(first_terms, by = \"id_bioguide\") %>%\n  mutate(period = date_part('year', age(term_start, first_term))) %>%\n  group_by(period) %>%\n  summarize(cohort_retained = sql(\"count(distinct id_bioguide)\")) \n\ncohorts %>%\n  collect(n = 10)\n\n# A tibble: 10 × 2\n   period cohort_retained\n    <dbl>           <int>\n 1      0           12518\n 2      1            3600\n 3      2            3619\n 4      3            1831\n 5      4            3210\n 6      5            1744\n 7      6            2385\n 8      7            1360\n 9      8            1607\n10      9            1028\n\n\n\nWITH \nfirst_terms AS (\n  SELECT id_bioguide, min(term_start) AS first_term\n  FROM legislators_terms \n  GROUP BY 1),\n\ncohorts AS (\n  SELECT date_part('year', age(b.term_start, a.first_term)) AS period,\n      count(distinct a.id_bioguide) as cohort_retained\n  FROM first_terms a\n  JOIN legislators_terms b on a.id_bioguide = b.id_bioguide \n  GROUP BY 1)\n  \nSELECT period,\n  first_value(cohort_retained) OVER (ORDER BY period) AS cohort_size,\n  cohort_retained,\n  cohort_retained * 1.0 / first_value(cohort_retained) OVER (ORDER BY period) AS pct_retained\nFROM cohorts;\n\n\nDisplaying records 1 - 10\n\n\nperiod\ncohort_size\ncohort_retained\npct_retained\n\n\n\n\n0\n12518\n12518\n1.0000000\n\n\n1\n12518\n3600\n0.2875859\n\n\n2\n12518\n3619\n0.2891037\n\n\n3\n12518\n1831\n0.1462694\n\n\n4\n12518\n3210\n0.2564307\n\n\n5\n12518\n1744\n0.1393194\n\n\n6\n12518\n2385\n0.1905256\n\n\n7\n12518\n1360\n0.1086436\n\n\n8\n12518\n1607\n0.1283751\n\n\n9\n12518\n1028\n0.0821217\n\n\n\n\n\n\nretained_data <-\n  cohorts %>%\n  window_order(period) %>%\n  mutate(cohort_size = first(cohort_retained)) %>%\n  mutate(pct_retained = cohort_retained * 1.0/cohort_size) %>%\n  select(period, cohort_size, cohort_retained, pct_retained) \n\nretained_data %>%\n  collect(n = 10)\n\n# A tibble: 10 × 4\n   period cohort_size cohort_retained pct_retained\n    <dbl>       <int>           <int>        <dbl>\n 1      0       12518           12518       1     \n 2      1       12518            3600       0.288 \n 3      2       12518            3619       0.289 \n 4      3       12518            1831       0.146 \n 5      4       12518            3210       0.256 \n 6      5       12518            1744       0.139 \n 7      6       12518            2385       0.191 \n 8      7       12518            1360       0.109 \n 9      8       12518            1607       0.128 \n10      9       12518            1028       0.0821\n\n\n\nretained_data %>%\n  ggplot(aes(x = period, y = pct_retained)) +\n  geom_line()\n\n\n\n\n\nWITH \nfirst_terms AS (\n  SELECT id_bioguide, min(term_start) AS first_term\n  FROM legislators_terms \n  GROUP BY 1),\n\ncohorts AS (\n  SELECT date_part('year', age(b.term_start, a.first_term)) AS period,\n      count(distinct a.id_bioguide) as cohort_retained\n  FROM first_terms a\n  JOIN legislators_terms b on a.id_bioguide = b.id_bioguide \n  GROUP BY 1),\n  \nretained_data AS (\n  SELECT period,\n    first_value(cohort_retained) OVER (ORDER BY period) AS cohort_size,\n    cohort_retained,\n    cohort_retained * 1.0 / first_value(cohort_retained) OVER (ORDER BY period) AS pct_retained\n  FROM cohorts)\n\nSELECT cohort_size,\n  max(case when period = 0 then pct_retained end) as yr0,\n  max(case when period = 1 then pct_retained end) as yr1,\n  max(case when period = 2 then pct_retained end) as yr2,\n  max(case when period = 3 then pct_retained end) as yr3,\n  max(case when period = 4 then pct_retained end) as yr4\nFROM retained_data\nGROUP BY 1;\n\n\n1 records\n\n\ncohort_size\nyr0\nyr1\nyr2\nyr3\nyr4\n\n\n\n\n12518\n1\n0.2875859\n0.2891037\n0.1462694\n0.2564307\n\n\n\n\n\n\nretained_data %>%\n  select(period, pct_retained) %>%\n  collect() %>%\n  arrange(period) %>%\n  pivot_wider(names_from = period, \n              names_prefix = \"yr\",\n              values_from = pct_retained) %>%\n  collect()\n\n# A tibble: 1 × 57\n    yr0   yr1   yr2   yr3   yr4   yr5   yr6   yr7   yr8    yr9  yr10   yr11\n  <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl> <dbl>  <dbl>\n1     1 0.288 0.289 0.146 0.256 0.139 0.191 0.109 0.128 0.0821 0.112 0.0733\n# … with 45 more variables: yr12 <dbl>, yr13 <dbl>, yr14 <dbl>, yr15 <dbl>,\n#   yr16 <dbl>, yr17 <dbl>, yr18 <dbl>, yr19 <dbl>, yr20 <dbl>, yr21 <dbl>,\n#   yr22 <dbl>, yr23 <dbl>, yr24 <dbl>, yr25 <dbl>, yr26 <dbl>, yr27 <dbl>,\n#   yr28 <dbl>, yr29 <dbl>, yr30 <dbl>, yr31 <dbl>, yr32 <dbl>, yr33 <dbl>,\n#   yr34 <dbl>, yr35 <dbl>, yr36 <dbl>, yr37 <dbl>, yr38 <dbl>, yr39 <dbl>,\n#   yr40 <dbl>, yr41 <dbl>, yr42 <dbl>, yr43 <dbl>, yr44 <dbl>, yr45 <dbl>,\n#   yr46 <dbl>, yr47 <dbl>, yr48 <dbl>, yr49 <dbl>, yr50 <dbl>, yr51 <dbl>, …\n\n\n\nWITH \nfirst_terms AS (\n  SELECT id_bioguide, min(term_start) AS first_term\n  FROM legislators_terms \n  GROUP BY 1)\n  \nSELECT a.id_bioguide, a.first_term, b.term_start, b.term_end,\n  c.date,\n  date_part('year',age(c.date, a.first_term)) AS period\nFROM first_terms a\nJOIN legislators_terms b ON a.id_bioguide = b.id_bioguide \nLEFT JOIN date_dim c ON c.date BETWEEN b.term_start and b.term_end \nand c.month_name = 'December' and c.day_of_month = 31;\n\n\nDisplaying records 1 - 10\n\n\nid_bioguide\nfirst_term\nterm_start\nterm_end\ndate\nperiod\n\n\n\n\nB000944\n1993-01-05\n1993-01-05\n1995-01-03\n1993-12-31\n0\n\n\nB000944\n1993-01-05\n1993-01-05\n1995-01-03\n1994-12-31\n1\n\n\nC000127\n1993-01-05\n1993-01-05\n1995-01-03\n1993-12-31\n0\n\n\nC000127\n1993-01-05\n1993-01-05\n1995-01-03\n1994-12-31\n1\n\n\nC000141\n1987-01-06\n1987-01-06\n1989-01-03\n1987-12-31\n0\n\n\nC000141\n1987-01-06\n1987-01-06\n1989-01-03\n1988-12-31\n1\n\n\nC000174\n1983-01-03\n1983-01-03\n1985-01-03\n1983-12-31\n0\n\n\nC000174\n1983-01-03\n1983-01-03\n1985-01-03\n1984-12-31\n1\n\n\nC001070\n2007-01-04\n2007-01-04\n2013-01-03\n2007-12-31\n0\n\n\nC001070\n2007-01-04\n2007-01-04\n2013-01-03\n2008-12-31\n1\n\n\n\n\n\n\nyear_ends <-\n  tbl(pg, sql(\"\n    SELECT generate_series::date AS date\n    FROM generate_series('1770-12-31', '2030-12-31', interval '1 year')\"))\n\ncohorts <-\n  first_terms %>%\n  inner_join(legislators_terms, by = join_by(id_bioguide)) %>%\n  left_join(year_ends, \n            by = join_by(between(y$date, x$term_start, x$term_end))) %>%\n  mutate(period = date_part('year', age(date, first_term))) %>%\n  select(id_bioguide, first_term, term_start, term_end, date, period) \n\ncohorts %>%\n  collect(n = 10) %>%\n  kable()\n\n\n\n\nid_bioguide\nfirst_term\nterm_start\nterm_end\ndate\nperiod\n\n\n\n\nB000944\n1993-01-05\n1993-01-05\n1995-01-03\n1993-12-31\n0\n\n\nB000944\n1993-01-05\n1993-01-05\n1995-01-03\n1994-12-31\n1\n\n\nC000127\n1993-01-05\n1993-01-05\n1995-01-03\n1993-12-31\n0\n\n\nC000127\n1993-01-05\n1993-01-05\n1995-01-03\n1994-12-31\n1\n\n\nC000141\n1987-01-06\n1987-01-06\n1989-01-03\n1987-12-31\n0\n\n\nC000141\n1987-01-06\n1987-01-06\n1989-01-03\n1988-12-31\n1\n\n\nC000174\n1983-01-03\n1983-01-03\n1985-01-03\n1983-12-31\n0\n\n\nC000174\n1983-01-03\n1983-01-03\n1985-01-03\n1984-12-31\n1\n\n\nC001070\n2007-01-04\n2007-01-04\n2013-01-03\n2007-12-31\n0\n\n\nC001070\n2007-01-04\n2007-01-04\n2013-01-03\n2008-12-31\n1\n\n\n\n\n\n\nyear_ends <- \n  tibble(date = seq(as.Date(\"1770-12-31\"), \n                    as.Date(\"2030-12-31\"), \n                    by = \"year\")) %>%\n  copy_inline(pg, .)\n\n\nWITH \nfirst_terms AS (\n  SELECT id_bioguide, min(term_start) AS first_term\n  FROM legislators_terms \n  GROUP BY 1),\n  \nyear_ends AS (\n  SELECT generate_series::date as date\n  FROM generate_series('1770-12-31', '2030-12-31', interval '1 year')\n)\n  \nSELECT \n  coalesce(date_part('year', age(c.date, a.first_term)), 0) AS period,\n  count(DISTINCT a.id_bioguide) AS cohort_retained\nFROM first_terms a\nJOIN legislators_terms b ON a.id_bioguide = b.id_bioguide \nLEFT JOIN year_ends c ON c.date BETWEEN b.term_start AND b.term_end \nGROUP BY 1;\n\n\nDisplaying records 1 - 10\n\n\nperiod\ncohort_retained\n\n\n\n\n0\n12518\n\n\n1\n12328\n\n\n2\n8166\n\n\n3\n8069\n\n\n4\n5862\n\n\n5\n5795\n\n\n6\n4361\n\n\n7\n4339\n\n\n8\n3521\n\n\n9\n3485\n\n\n\n\n\n\nWITH \nfirst_terms AS (\n  SELECT id_bioguide, min(term_start) AS first_term\n  FROM legislators_terms \n  GROUP BY 1),\n  \ncohorts AS (\n  SELECT * \n  FROM first_terms a\n  JOIN legislators_terms b USING (id_bioguide)\n  LEFT JOIN date_dim c ON c.date BETWEEN b.term_start AND b.term_end \n    AND c.month_name = 'December' AND c.day_of_month = 31)\n  \nSELECT \n  coalesce(date_part('year', age(date, first_term)), 0) AS period,\n  count(DISTINCT id_bioguide) AS cohort_retained\nFROM cohorts\nGROUP BY 1;\n\n\nDisplaying records 1 - 10\n\n\nperiod\ncohort_retained\n\n\n\n\n0\n12518\n\n\n1\n12328\n\n\n2\n8166\n\n\n3\n8069\n\n\n4\n5862\n\n\n5\n5795\n\n\n6\n4361\n\n\n7\n4339\n\n\n8\n3521\n\n\n9\n3485\n\n\n\n\n\n\ncohorts_retained <-\n  cohorts %>%\n  mutate(period = coalesce(date_part('year', age(date, first_term)), 0)) %>%\n  select(period, id_bioguide) %>%\n  distinct() %>%\n  group_by(period) %>%\n  summarize(cohort_retained = n()) %>%\n  arrange(period)\n\ncohorts_retained %>%\n  collect(n = 10) %>%\n  kable()\n\n\n\n\nperiod\ncohort_retained\n\n\n\n\n0\n12518\n\n\n1\n12328\n\n\n2\n8166\n\n\n3\n8069\n\n\n4\n5862\n\n\n5\n5795\n\n\n6\n4361\n\n\n7\n4339\n\n\n8\n3521\n\n\n9\n3485\n\n\n\n\n\n\nWITH \nfirst_terms AS (\n  SELECT id_bioguide, min(term_start) AS first_term\n  FROM legislators_terms \n  GROUP BY 1)\n  \nSELECT id_bioguide, a.first_term, b.term_start,\n  CASE WHEN b.term_type = 'rep' THEN b.term_start + interval '2 years'\n       WHEN b.term_type = 'sen' THEN b.term_start + interval '6 years'\n  END AS term_end\nFROM first_terms a\nJOIN legislators_terms b USING (id_bioguide);\n\n\nDisplaying records 1 - 10\n\n\nid_bioguide\nfirst_term\nterm_start\nterm_end\n\n\n\n\nB000944\n1993-01-05\n1993-01-05\n1995-01-05\n\n\nC000127\n1993-01-05\n1993-01-05\n1995-01-05\n\n\nC000141\n1987-01-06\n1987-01-06\n1989-01-06\n\n\nC000174\n1983-01-03\n1983-01-03\n1985-01-03\n\n\nC001070\n2007-01-04\n2007-01-04\n2013-01-04\n\n\nF000062\n1992-11-10\n1992-11-10\n1998-11-10\n\n\nF000469\n2019-01-03\n2019-01-03\n2021-01-03\n\n\nK000367\n2007-01-04\n2007-01-04\n2013-01-04\n\n\nM000639\n1993-01-05\n1993-01-05\n1995-01-05\n\n\nS000033\n1991-01-03\n1991-01-03\n1993-01-03\n\n\n\n\n\n\nfirst_terms %>%\n  inner_join(legislators_terms, by = join_by(id_bioguide)) %>%\n  mutate(term_end = \n           case_when(term_type == 'rep' ~ term_start + years(2),\n                     term_type == 'sen' ~ term_start + years(6))) %>%\n  select(id_bioguide, first_term, term_start, term_end)  %>%\n  collect(n = 10) %>%\n  kable()\n\n\n\n\nid_bioguide\nfirst_term\nterm_start\nterm_end\n\n\n\n\nB000944\n1993-01-05\n1993-01-05\n1995-01-05\n\n\nC000127\n1993-01-05\n1993-01-05\n1995-01-05\n\n\nC000141\n1987-01-06\n1987-01-06\n1989-01-06\n\n\nC000174\n1983-01-03\n1983-01-03\n1985-01-03\n\n\nC001070\n2007-01-04\n2007-01-04\n2013-01-04\n\n\nF000062\n1992-11-10\n1992-11-10\n1998-11-10\n\n\nF000469\n2019-01-03\n2019-01-03\n2021-01-03\n\n\nK000367\n2007-01-04\n2007-01-04\n2013-01-04\n\n\nM000639\n1993-01-05\n1993-01-05\n1995-01-05\n\n\nS000033\n1991-01-03\n1991-01-03\n1993-01-03"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Tanimura, C. 2021. SQL for Data Analysis. O’Reilly Media. https://books.google.com.au/books?id=ojhCEAAAQBAJ."
  }
]