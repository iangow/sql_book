---
title: "Exercise template for 'Beaver (1968)'"
author: Priyaa
format: html
---

```{r}
library(dplyr, warn.conflicts = FALSE)
library(DBI)
library(ggplot2)

pg <- dbConnect(RPostgres::Postgres(), bigint = "integer")
```

## Important instructions

The `wrds_data` chunk below takes a couple of minutes to run.
According, it has been set with `cache: true`.
When a code chunk is cached, it is re-run only if the code is changed; if the code is unchanged, when compiling this file R will use the cached results from the previous time the code was run.
You should not need to edit the code in this chunk in preparing your answers.
Only the last couple of questions relate to code run using this template.
When you download this template, you should compile it before editing.
If you encounter errors in running the unedited template, please let me know ASAP.
I highly recommend that you use an RStudio "project" to organize your work for *Financial Accounting Research*.

## Market reactions to earnings announcements

### Discussion questions

1. How do the research questions of @Beaver:1968vf and @Ball:1968ub differ?
If there is overlap, do you think that one paper provides superior evidence to the other?
Or are they just different?

@Ball:1968ub looked at weather accounting numbers were useful. In investigating this, this paper distinguished expected changes and unexpected changes in accounting incomes to estimate the abnormal return and changes in unexpected accounting incomes. @Beaver:1968vf had a more specific research question where they primarily wanted to investigate the extent to which common stock investors perceive earnings to possess informational value. There is a large overlap between the research questions of both papers. Both papers provide good evidence to show that accounting earnings information is useful. 

2. What differences are there in the data (e.g., sample period) used in  @Beaver:1968vf from the data used in @Ball:1968ub?
Why do these differences exist?

In @Ball:1968ub, the inclusion criteria stated that the firms included must have a fiscal year ending December 31. However in @Beaver:1968vf, the firms included had to have a fiscal year that ended on a date other than December 31. 

This criterion was selected in @Beaver:1968vf to avoid a clustering of announcement dates during any time period.

3. Do the reasons given by @Beaver:1968vf for his sample selection criteria seem reasonable? 
Do you think these were made prior to looking at results? (Why or why not?)
Does it matter at what stage in the research process these decisions were made?

The reasons seemed a little unreasonable. By eliminating firms that had dividend announcements or stock splits announced during the earnings announcement week, he created a very small sample that is not representative of the market as a whole. 

4. Which do you think is the better variable---price or volume---for addressing the research questions of @Beaver:1968vf?
Do you think it is helpful to have both variables?

Volume is a better variable in terms of addressing the research question. This is because when observing price, there may be a portion of price activity that cannot be attributed to the earnings announcement. This is because price changes may occur due to more 'action' in the security as stated by @Beaver:1968vf. 

However, observing both variables gives a better picture of the expectations of individual investors and the expectations of the market as a whole being altered by the earnings report. 

5. @Beaver:1968vf compares event-week volume and volatility with their average equivalents in non-event periods.
@Ball:2008un "quantify the relative importance of earnings announcements in providing new information to the share market" and argue that earnings announcements provide relatively little of this information.
If volume is a measure of information content, what does Figure 1 of @Beaver:1968vf imply regarding the proportion of information conveyed during earnings announcement weeks?
Can this be reconciled with reported results in @Beaver:1968vf and the arguments in @Ball:2008un?

Figure 1 indicates that there is a dramatic increase in volume in the announcement week. This shows that investors shift their portfolio positions at the time of the earnings announcement and this shift is consistent with the contention that earnings reports have information content. 

This cannot be reconciled with @Ball:2008un as they argue that earnings announcements provide relatively little of this information. 

6. @Beaver:1968vf discusses the statistical significance of his results on p. 77 (residual volume analysis) and pp. 81-82 (return residual analysis).
Why do think @Beaver:1968vf uses the approaches discussed there?
How might you evaluate statistical significance more formally if you were writing the paper today?

@Beaver:1968vf uses this approach because the comparison of mean values can be misleading. If the paper was written today, we might use a regression analysis and carry out a significance test. 

7. The primary analyses in @Beaver:1968vf are provided in plots.
While the cost of producing plots has surely plummeted since 1968, we generally do not see primary analyses presented as plots today.
Why do you think this is the case?

## A re-evaluation of @Beaver:1968vf


```{r}
#| include: false
library(dplyr, warn.conflicts = FALSE)
library(DBI)
library(ggplot2)
library(lubridate)
library(tidyr)
library(farr)
library(dbplyr)     # For copy_inline()
```

```{r wrds_data}
#| message: false
#| cache: true
#| include: false
pg <- dbConnect(RPostgres::Postgres(), bigint = "integer")

fundq <- tbl(pg, sql("SELECT * FROM comp.fundq"))

first_date <- "2010-01-01"
last_date <- "2019-12-31"

earn_annc_dates <-
  fundq %>%
  filter(indfmt == "INDL", datafmt == "STD",
         consol == "C", popsrc == "D") %>%
  filter(!is.na(rdq), fqtr==4L) %>%
  select(gvkey, datadate, rdq) %>%
  filter(between(datadate, first_date, last_date)) %>%
  collect()

ccmxpf_lnkhist <- tbl(pg, sql("SELECT * FROM crsp.ccmxpf_lnkhist"))

ccm_link <-
  ccmxpf_lnkhist %>%
  filter(linktype %in% c("LC", "LU", "LS"),
         linkprim %in% c("C", "P")) %>%
  rename(permno = lpermno) %>%
  collect()

dsi <- tbl(pg, sql("SELECT * FROM crsp.dsi"))

trading_dates <-
  dsi %>%
  select(date) %>%
  collect() %>%
  arrange(date) %>%
  mutate(td = row_number())

annc_dates <-
  tibble(annc_date = seq(min(trading_dates$date), 
                         max(trading_dates$date), 1)) %>%
  left_join(trading_dates, by = c("annc_date"="date")) %>%
  fill(td, .direction = "up")

days_before <- 20L
days_after <- 20L

dsf <- tbl(pg, sql("SELECT * FROM crsp.dsf"))

mkt_rets <-
  dsf %>%
  inner_join(dsi, by = "date") %>%
  mutate(ret_mkt = ret - vwretd) %>%
  select(permno, date, ret, ret_mkt, vol)

stocknames <- tbl(pg, sql("SELECT * FROM crsp.stocknames"))

nyse <-
  stocknames %>% 
  filter(exchcd==1) %>%
  select(permno, namedt, nameenddt) %>%
  collect()

earn_annc_links <-
  earn_annc_dates %>%
  left_join(ccm_link, by = "gvkey", multiple = "all") %>%
  filter(datadate >= linkdt, 
         rdq <= linkenddt | is.na(linkenddt)) %>%
  inner_join(nyse, by = "permno", multiple = "all") %>%
  filter(rdq >= namedt, rdq <= nameenddt) %>%
  select(gvkey, datadate, rdq, permno)

earn_annc_windows <-
  earn_annc_dates %>%
  inner_join(annc_dates, by = c("rdq"="annc_date")) %>%
  mutate(start_td = td - days_before, 
         end_td = td + days_after) %>%
  inner_join(trading_dates, by = c("start_td"="td")) %>%
  rename(start_date = date) %>%
  inner_join(trading_dates, by = c("end_td"="td")) %>%
  select(-start_td, -end_td) %>%
  rename(end_date = date,
         event_td = td)

earn_annc_window_permnos <-
  earn_annc_windows %>%
  inner_join(earn_annc_links, by = c("gvkey", "datadate", "rdq"))

earn_annc_crsp <-
  copy_inline(pg, earn_annc_window_permnos) %>%
  inner_join(mkt_rets, by = "permno") %>%
  filter(date >= start_date, date <= end_date) %>%
  select(gvkey, datadate, rdq, event_td, date, ret, ret_mkt, vol) %>%
  collect()
```

```{r ret_data}
#| include: false
earn_annc_rets <-
  earn_annc_crsp %>%
  inner_join(trading_dates, by = "date") %>%
  mutate(relative_td = td - event_td) 
```

```{r ret-data-vols}
#| include: false
earn_annc_vols <-
  earn_annc_rets %>%
  group_by(gvkey, datadate) %>%
  mutate(avg_vol = mean(vol, na.rm = TRUE)) %>%
  mutate(rel_vol = vol/avg_vol,
         year = year(datadate)) %>%
  ungroup() 
```

```{r ret-summ}
#| include: false
earn_annc_summ <-
  earn_annc_vols %>%
  group_by(relative_td, year) %>%
  summarize(obs = n(),
            mean_ret = mean(ret, na.rm = TRUE),
            mean_ret_mkt = mean(ret_mkt, na.rm = TRUE),
            mean_rel_vol = mean(rel_vol, na.rm = TRUE),
            sd_ret = sd(ret, na.rm = TRUE),
            sd_ret_mkt = sd(ret_mkt, na.rm = TRUE),
            mad_ret = mad(ret, na.rm = TRUE),
            mad_ret_mkt = mad(ret_mkt, na.rm = TRUE),
            .groups = "drop")
```

## Discussion questions

1. After reading @Bamber:2000wv, do the reasons given by @Beaver:1968vf for his sample selection criteria still seem reasonable? 
Why or why not?

The reasons given by @Beaver:1968vf are not reasonable. This is because he created a very small sample of firms that does not give a reasonable representation of the market and how the market reacts to earnings announcements. 

2. @Bamber:2000wv do a replication and an extension of @Beaver:1968vf.
Why was it important to include the replication?
What alternative approaches to extension could @Bamber:2000wv have considered? 
Does it make sense to limit extensions to the sample period, available data, and methods of @Beaver:1968vf?
What do you think of the claim that "the first research bricks [i.e., @Beaver:1968vf] affect the whole wall [of accounting research]"?

The replication gives us an idea of what the biased results would look like. By performing both a replication and an extension, we are able to see how different the results are from each other. This gives us a better understanding on weather @Beaver:1968vf was biased. 

It makes sense to limit extensions to the sample period, available data, and methods of @Beaver:1968vf because it provides better comparability when comparing @Beaver:1968vf and the extension done by @Bamber:2000wv. 

The claim that "the first research bricks [i.e., @Beaver:1968vf] affect the whole wall [of accounting research]" shows us that the first few studies done in accounting form the basis of the thought process in future research. 

3. What's the basic conclusion from the plots above in terms of whether "earnings announcements convey new information to the market"?
Do the results support the conclusions made by subsequent researchers based on @Beaver:1968vf?
Or do the concerns of @Bamber:2000wv remain applicable?

Based on @Bamber:2000wv, the plots show that there is little evidence of an unusual price reaction for most of the earnings announcements. The plots show that the information content inference regarding the Fortune 200 earnings announcement is attributable to a small proportion of announcements. 

4. In our replication analysis above, we made a number of measurement and design choices that differed from those made by @Beaver:1968vf.
What are those differences?
Do you expect these to materially affect the tenor of the results?
Do the choices we made seem appropriate if we were writing a research paper?

One of the design choices made that is different is the assumption that if a firm announces earnings on a trading date, then that date will be trading date zero. 

This may not materially affect the results but it may not be appropriate if it was used in writing a research paper. 

5. The plots above use *daily* data [@Beaver:1968vf used weekly data].
Apart from more **statistical power**, do the daily plots provide novel insights in this case?

The daily plots do provide novel insights in this case because we are able to understand any movements before and after trading day. Thus we are able to view if there are changes in volume and price before the announcement date. 

6. What does the variable `mad_ret_mkt` on the data frame `earn_annc_summ` represent?
Do results look different if this variable is used?
Does this address the first concern about research design that @Bamber:2000wv raise?
If not, can you suggest (and apply) and alternative measure?

The mad R function computes the median absolute deviation. Hence, 'mad_ret_mkt' is the mean absolute deviation of the ret_mkt values. 

7. In the plots above, two filters have been applied: `year > 2010` and `year < 2019)`.
Does it make sense to remove one or the other of these filters?
What do you observe if you remove one or both of these?
Can you explain these observations?

It would not make sense to remove the year<2019 filter because the data after 2019 would be affected by COVID-19. 